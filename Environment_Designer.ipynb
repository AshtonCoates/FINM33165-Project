{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Building for Earnings Event-Driven RL Trading\n",
    "\n",
    "## Overview\n",
    "Complete RL environment with proper State, Action, Reward definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('✓ Libraries imported successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load CSV Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded 14,815 rows from earnings_events_data.csv\n",
      "  - Total Events: 138\n",
      "  - Date Range: 2019-01-25 00:00:00+00:00 to 2024-11-05 23:00:00+00:00\n"
     ]
    }
   ],
   "source": [
    "CSV_PATH = 'earnings_events_data.csv'\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df['earnings_date'] = pd.to_datetime(df['earnings_date'])\n",
    "\n",
    "print(f'✓ Loaded {len(df):,} rows from {CSV_PATH}')\n",
    "print(f'  - Total Events: {df[\"event_id\"].nunique()}')\n",
    "print(f'  - Date Range: {df[\"timestamp\"].min()} to {df[\"timestamp\"].max()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define State, Action, and Reward\n",
    "\n",
    "### ENVIRONMENT SPECIFICATION - Complete Definition Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "╔════════════════════════════════════════════════════════════════════════════════╗\n",
      "║                    STATE SPACE DEFINITION                                       ║\n",
      "╚════════════════════════════════════════════════════════════════════════════════╝\n",
      "\n",
      "State is a 7-dimensional vector:\n",
      "\n",
      "  state = [momentum, volatility, pre_close, current_price, position, cash, window_pnl]\n",
      "           [   0   ,      1     ,     2    ,       3     ,    4    ,  5  ,   6   ]\n",
      "\n",
      "• state[0] - momentum: Pre-earnings 3-day momentum (float)\n",
      "• state[1] - volatility: Pre-earnings 3-day volatility (float)\n",
      "• state[2] - pre_close: Closing price before earnings ($)\n",
      "• state[3] - current_price: Current price at this step ($)\n",
      "• state[4] - position: Trading position (0=flat, 1=long)\n",
      "• state[5] - cash: Available cash ($)\n",
      "• state[6] - window_pnl: Event Window PnL (%)\n",
      "\n",
      "Observation Space: Box(shape=(7,), dtype=float32)\n",
      "\n",
      "\n",
      "╔════════════════════════════════════════════════════════════════════════════════╗\n",
      "║                    ACTION SPACE DEFINITION                                      ║\n",
      "╚════════════════════════════════════════════════════════════════════════════════╝\n",
      "\n",
      "Action is a discrete choice among 3 actions:\n",
      "\n",
      "  action = 0: HOLD  - Do nothing (always available)\n",
      "  action = 1: BUY   - Enter long position (only if flat)\n",
      "  action = 2: SELL  - Exit long position (only if long)\n",
      "\n",
      "Action Space: Discrete(3)\n",
      "Transaction Cost: 0.05% (0.0005)\n",
      "\n",
      "\n",
      "╔════════════════════════════════════════════════════════════════════════════════╗\n",
      "║                    REWARD DEFINITION                                            ║\n",
      "╚════════════════════════════════════════════════════════════════════════════════╝\n",
      "\n",
      "Reward is based on EVENT WINDOW PnL (not individual trades):\n",
      "\n",
      "• During episode (intermediate steps):\n",
      "  reward = 0\n",
      "\n",
      "• At episode end (done=True):\n",
      "  reward = (final_portfolio_value - initial_cash) / initial_cash\n",
      "  This is the total Event Window PnL\n",
      "\n",
      "Reward Range: [-0.3, 0.3] (typical)\n",
      "\n",
      "Example:\n",
      "  • Buy at 150, Sell at 153 in event window\n",
      "  • After transaction costs: ~1.8% profit\n",
      "  • Final reward: 0.018 (at episode end)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('''\n",
    "╔════════════════════════════════════════════════════════════════════════════════╗\n",
    "║                    STATE SPACE DEFINITION                                       ║\n",
    "╚════════════════════════════════════════════════════════════════════════════════╝\n",
    "\n",
    "State is a 7-dimensional vector:\n",
    "\n",
    "  state = [momentum, volatility, pre_close, current_price, position, cash, window_pnl]\n",
    "           [   0   ,      1     ,     2    ,       3     ,    4    ,  5  ,   6   ]\n",
    "\n",
    "• state[0] - momentum: Pre-earnings 3-day momentum (float)\n",
    "• state[1] - volatility: Pre-earnings 3-day volatility (float)\n",
    "• state[2] - pre_close: Closing price before earnings ($)\n",
    "• state[3] - current_price: Current price at this step ($)\n",
    "• state[4] - position: Trading position (0=flat, 1=long)\n",
    "• state[5] - cash: Available cash ($)\n",
    "• state[6] - window_pnl: Event Window PnL (%)\n",
    "\n",
    "Observation Space: Box(shape=(7,), dtype=float32)\n",
    "''')\n",
    "\n",
    "print('''\n",
    "╔════════════════════════════════════════════════════════════════════════════════╗\n",
    "║                    ACTION SPACE DEFINITION                                      ║\n",
    "╚════════════════════════════════════════════════════════════════════════════════╝\n",
    "\n",
    "Action is a discrete choice among 3 actions:\n",
    "\n",
    "  action = 0: HOLD  - Do nothing (always available)\n",
    "  action = 1: BUY   - Enter long position (only if flat)\n",
    "  action = 2: SELL  - Exit long position (only if long)\n",
    "\n",
    "Action Space: Discrete(3)\n",
    "Transaction Cost: 0.05% (0.0005)\n",
    "''')\n",
    "\n",
    "print('''\n",
    "╔════════════════════════════════════════════════════════════════════════════════╗\n",
    "║                    REWARD DEFINITION                                            ║\n",
    "╚════════════════════════════════════════════════════════════════════════════════╝\n",
    "\n",
    "Reward is based on EVENT WINDOW PnL (not individual trades):\n",
    "\n",
    "• During episode (intermediate steps):\n",
    "  reward = 0\n",
    "\n",
    "• At episode end (done=True):\n",
    "  reward = (final_portfolio_value - initial_cash) / initial_cash\n",
    "  This is the total Event Window PnL\n",
    "\n",
    "Reward Range: [-0.3, 0.3] (typical)\n",
    "\n",
    "Example:\n",
    "  • Buy at 150, Sell at 153 in event window\n",
    "  • After transaction costs: ~1.8% profit\n",
    "  • Final reward: 0.018 (at episode end)\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Define EarningsEventEnv Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ EarningsEventEnv class defined successfully\n"
     ]
    }
   ],
   "source": [
    "class EarningsEventEnv(gym.Env):\n",
    "    '''Trading environment for earnings event-driven strategy.'''\n",
    "    \n",
    "    def __init__(self, event_data, transaction_cost=0.0005, initial_cash=10000):\n",
    "        super(EarningsEventEnv, self).__init__()\n",
    "        \n",
    "        self.event_data = event_data.sort_values('timestamp').reset_index(drop=True)\n",
    "        self.transaction_cost = transaction_cost\n",
    "        self.initial_cash = initial_cash\n",
    "        \n",
    "        # Extract metadata\n",
    "        self.ticker = event_data['ticker_event'].iloc[0]\n",
    "        self.earnings_date = event_data['earnings_date'].iloc[0]\n",
    "        self.event_id = event_data['event_id'].iloc[0]\n",
    "        self.momentum = event_data['momentum'].iloc[0]\n",
    "        self.volatility = event_data['volatility'].iloc[0]\n",
    "        self.pre_close = event_data['pre_close'].iloc[0]\n",
    "        \n",
    "        # Define spaces\n",
    "        self.action_space = spaces.Discrete(3)\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(7,), dtype=np.float32)\n",
    "        \n",
    "        # Initialize state\n",
    "        self.current_step = 0\n",
    "        self.position = 0\n",
    "        self.cash = initial_cash\n",
    "        self.trades = []\n",
    "    \n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        self.position = 0\n",
    "        self.cash = self.initial_cash\n",
    "        self.trades = []\n",
    "        return self._get_observation()\n",
    "    \n",
    "    def _get_observation(self):\n",
    "        if self.current_step >= len(self.event_data):\n",
    "            current_price = self.event_data['close'].iloc[-1]\n",
    "        else:\n",
    "            current_price = self.event_data['close'].iloc[self.current_step]\n",
    "        \n",
    "        portfolio_value = self.cash + (self.position * current_price)\n",
    "        window_pnl = (portfolio_value - self.initial_cash) / self.initial_cash\n",
    "        \n",
    "        state = np.array([\n",
    "            self.momentum,\n",
    "            self.volatility,\n",
    "            self.pre_close,\n",
    "            current_price,\n",
    "            float(self.position),\n",
    "            self.cash,\n",
    "            window_pnl\n",
    "        ], dtype=np.float32)\n",
    "        return state\n",
    "    \n",
    "    def step(self, action):\n",
    "        current_price = self.event_data['close'].iloc[self.current_step]\n",
    "        reward = 0\n",
    "        \n",
    "        if action == 1 and self.position == 0:\n",
    "            cost = current_price * (1 + self.transaction_cost)\n",
    "            if self.cash >= cost:\n",
    "                self.position = 1\n",
    "                self.cash -= cost\n",
    "                self.trades.append({'action': 'buy', 'price': current_price})\n",
    "        \n",
    "        elif action == 2 and self.position == 1:\n",
    "            proceeds = current_price * (1 - self.transaction_cost)\n",
    "            self.cash += proceeds\n",
    "            self.position = 0\n",
    "            self.trades.append({'action': 'sell', 'price': current_price})\n",
    "        \n",
    "        self.current_step += 1\n",
    "        done = (self.current_step >= len(self.event_data))\n",
    "        \n",
    "        if done and self.position == 1:\n",
    "            final_price = self.event_data['close'].iloc[-1]\n",
    "            self.cash += final_price * (1 - self.transaction_cost)\n",
    "            self.position = 0\n",
    "        \n",
    "        if done:\n",
    "            final_value = self.cash\n",
    "            reward = (final_value - self.initial_cash) / self.initial_cash\n",
    "        \n",
    "        observation = self._get_observation()\n",
    "        return observation, reward, done, {}\n",
    "    \n",
    "    def get_window_pnl(self):\n",
    "        portfolio = self.cash + (self.position * self.event_data['close'].iloc[-1])\n",
    "        return (portfolio - self.initial_cash) / self.initial_cash\n",
    "\n",
    "print('✓ EarningsEventEnv class defined successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Create Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Events: 138\n",
      "Train Events: 110\n",
      "Test Events: 28\n",
      "\n",
      "✓ Created 110 training + 28 test environments\n"
     ]
    }
   ],
   "source": [
    "# Extract unique events\n",
    "events = df.groupby('event_id').first().reset_index()\n",
    "train_events = events[events['split'] == 'train']\n",
    "test_events = events[events['split'] == 'test']\n",
    "\n",
    "print(f'Total Events: {len(events)}')\n",
    "print(f'Train Events: {len(train_events)}')\n",
    "print(f'Test Events: {len(test_events)}')\n",
    "\n",
    "# Create environments\n",
    "train_envs = {}\n",
    "for event_id in train_events['event_id']:\n",
    "    event_data = df[df['event_id'] == event_id]\n",
    "    train_envs[event_id] = EarningsEventEnv(event_data)\n",
    "\n",
    "test_envs = {}\n",
    "for event_id in test_events['event_id']:\n",
    "    event_data = df[df['event_id'] == event_id]\n",
    "    test_envs[event_id] = EarningsEventEnv(event_data)\n",
    "\n",
    "print(f'\\n✓ Created {len(train_envs)} training + {len(test_envs)} test environments')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Test Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial State: [1.15539384e-04 5.19670604e-04 1.73520004e+02 1.68850006e+02\n",
      " 0.00000000e+00 1.00000000e+04 0.00000000e+00]\n",
      "State Shape: (7,)\n",
      "State Type: float32\n",
      "\n",
      "After 10 steps:\n",
      "  Reward (intermediate): 0\n",
      "  Position: 1\n",
      "  Cash: $9829.69\n",
      "  Window PnL: 0.0013\n"
     ]
    }
   ],
   "source": [
    "env = train_envs[list(train_envs.keys())[0]]\n",
    "state = env.reset()\n",
    "\n",
    "print(f'Initial State: {state}')\n",
    "print(f'State Shape: {state.shape}')\n",
    "print(f'State Type: {state.dtype}')\n",
    "\n",
    "# Run a few steps\n",
    "done = False\n",
    "step = 0\n",
    "while not done and step < 10:\n",
    "    action = np.random.choice([0, 1, 2])\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    step += 1\n",
    "\n",
    "print(f'\\nAfter {step} steps:')\n",
    "print(f'  Reward (intermediate): {reward}')\n",
    "print(f'  Position: {env.position}')\n",
    "print(f'  Cash: ${env.cash:.2f}')\n",
    "print(f'  Window PnL: {env.get_window_pnl():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
