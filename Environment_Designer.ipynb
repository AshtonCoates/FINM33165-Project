{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Building for Earnings Event-Driven RL Trading\n",
    "\n",
    "## Overview\n",
    "Complete RL environment with proper State, Action, Reward definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('\u2713 Libraries imported successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load CSV Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH = 'earnings_events_data.csv'\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df['earnings_date'] = pd.to_datetime(df['earnings_date'])\n",
    "\n",
    "print(f'\u2713 Loaded {len(df):,} rows from {CSV_PATH}')\n",
    "print(f'  - Total Events: {df[\"event_id\"].nunique()}')\n",
    "print(f'  - Date Range: {df[\"timestamp\"].min()} to {df[\"timestamp\"].max()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define State, Action, and Reward\n",
    "\n",
    "### ENVIRONMENT SPECIFICATION - Complete Definition Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('''\n",
    "\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n",
    "\u2551                    STATE SPACE DEFINITION                                       \u2551\n",
    "\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n",
    "\n",
    "State is a 7-dimensional vector:\n",
    "\n",
    "  state = [momentum, volatility, pre_close, current_price, position, cash, window_pnl]\n",
    "           [   0   ,      1     ,     2    ,       3     ,    4    ,  5  ,   6   ]\n",
    "\n",
    "\u2022 state[0] - momentum: Pre-earnings 3-day momentum (float)\n",
    "\u2022 state[1] - volatility: Pre-earnings 3-day volatility (float)\n",
    "\u2022 state[2] - pre_close: Closing price before earnings ($)\n",
    "\u2022 state[3] - current_price: Current price at this step ($)\n",
    "\u2022 state[4] - position: Trading position (0=flat, 1=long)\n",
    "\u2022 state[5] - cash: Available cash ($)\n",
    "\u2022 state[6] - window_pnl: Event Window PnL (%)\n",
    "\n",
    "Observation Space: Box(shape=(7,), dtype=float32)\n",
    "''')\n",
    "\n",
    "print('''\n",
    "\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n",
    "\u2551                    ACTION SPACE DEFINITION                                      \u2551\n",
    "\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n",
    "\n",
    "Action is a discrete choice among 3 actions:\n",
    "\n",
    "  action = 0: HOLD  - Do nothing (always available)\n",
    "  action = 1: BUY   - Enter long position (only if flat)\n",
    "  action = 2: SELL  - Exit long position (only if long)\n",
    "\n",
    "Action Space: Discrete(3)\n",
    "Transaction Cost: 0.05% (0.0005)\n",
    "''')\n",
    "\n",
    "print('''\n",
    "\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n",
    "\u2551                    REWARD DEFINITION                                            \u2551\n",
    "\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n",
    "\n",
    "Reward is based on EVENT WINDOW PnL (not individual trades):\n",
    "\n",
    "\u2022 During episode (intermediate steps):\n",
    "  reward = 0\n",
    "\n",
    "\u2022 At episode end (done=True):\n",
    "  reward = (final_portfolio_value - initial_cash) / initial_cash\n",
    "  This is the total Event Window PnL\n",
    "\n",
    "Reward Range: [-0.3, 0.3] (typical)\n",
    "\n",
    "Example:\n",
    "  \u2022 Buy at 150, Sell at 153 in event window\n",
    "  \u2022 After transaction costs: ~1.8% profit\n",
    "  \u2022 Final reward: 0.018 (at episode end)\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Define EarningsEventEnv Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarningsEventEnv(gym.Env):\n",
    "    '''Trading environment for earnings event-driven strategy.'''\n",
    "    \n",
    "    def __init__(self, event_data, transaction_cost=0.0005, initial_cash=10000):\n",
    "        super(EarningsEventEnv, self).__init__()\n",
    "        \n",
    "        self.event_data = event_data.sort_values('timestamp').reset_index(drop=True)\n",
    "        self.transaction_cost = transaction_cost\n",
    "        self.initial_cash = initial_cash\n",
    "        \n",
    "        # Extract metadata\n",
    "        self.ticker = event_data['ticker_event'].iloc[0]\n",
    "        self.earnings_date = event_data['earnings_date'].iloc[0]\n",
    "        self.event_id = event_data['event_id'].iloc[0]\n",
    "        self.momentum = event_data['momentum'].iloc[0]\n",
    "        self.volatility = event_data['volatility'].iloc[0]\n",
    "        self.pre_close = event_data['pre_close'].iloc[0]\n",
    "        \n",
    "        # Define spaces\n",
    "        self.action_space = spaces.Discrete(3)\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(7,), dtype=np.float32)\n",
    "        \n",
    "        # Initialize state\n",
    "        self.current_step = 0\n",
    "        self.position = 0\n",
    "        self.cash = initial_cash\n",
    "        self.trades = []\n",
    "    \n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        self.position = 0\n",
    "        self.cash = self.initial_cash\n",
    "        self.trades = []\n",
    "        return self._get_observation()\n",
    "    \n",
    "    def _get_observation(self):\n",
    "        if self.current_step >= len(self.event_data):\n",
    "            current_price = self.event_data['close'].iloc[-1]\n",
    "        else:\n",
    "            current_price = self.event_data['close'].iloc[self.current_step]\n",
    "        \n",
    "        portfolio_value = self.cash + (self.position * current_price)\n",
    "        window_pnl = (portfolio_value - self.initial_cash) / self.initial_cash\n",
    "        \n",
    "        state = np.array([\n",
    "            self.momentum,\n",
    "            self.volatility,\n",
    "            self.pre_close,\n",
    "            current_price,\n",
    "            float(self.position),\n",
    "            self.cash,\n",
    "            window_pnl\n",
    "        ], dtype=np.float32)\n",
    "        return state\n",
    "    \n",
    "    def step(self, action):\n",
    "        current_price = self.event_data['close'].iloc[self.current_step]\n",
    "        reward = 0\n",
    "        \n",
    "        if action == 1 and self.position == 0:\n",
    "            cost = current_price * (1 + self.transaction_cost)\n",
    "            if self.cash >= cost:\n",
    "                self.position = 1\n",
    "                self.cash -= cost\n",
    "                self.trades.append({'action': 'buy', 'price': current_price})\n",
    "        \n",
    "        elif action == 2 and self.position == 1:\n",
    "            proceeds = current_price * (1 - self.transaction_cost)\n",
    "            self.cash += proceeds\n",
    "            self.position = 0\n",
    "            self.trades.append({'action': 'sell', 'price': current_price})\n",
    "        \n",
    "        self.current_step += 1\n",
    "        done = (self.current_step >= len(self.event_data))\n",
    "        \n",
    "        if done and self.position == 1:\n",
    "            final_price = self.event_data['close'].iloc[-1]\n",
    "            self.cash += final_price * (1 - self.transaction_cost)\n",
    "            self.position = 0\n",
    "        \n",
    "        if done:\n",
    "            final_value = self.cash\n",
    "            reward = (final_value - self.initial_cash) / self.initial_cash\n",
    "        \n",
    "        observation = self._get_observation()\n",
    "        return observation, reward, done, {}\n",
    "    \n",
    "    def get_window_pnl(self):\n",
    "        portfolio = self.cash + (self.position * self.event_data['close'].iloc[-1])\n",
    "        return (portfolio - self.initial_cash) / self.initial_cash\n",
    "\n",
    "print('\u2713 EarningsEventEnv class defined successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Create Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique events\n",
    "events = df.groupby('event_id').first().reset_index()\n",
    "train_events = events[events['split'] == 'train']\n",
    "test_events = events[events['split'] == 'test']\n",
    "\n",
    "print(f'Total Events: {len(events)}')\n",
    "print(f'Train Events: {len(train_events)}')\n",
    "print(f'Test Events: {len(test_events)}')\n",
    "\n",
    "# Create environments\n",
    "train_envs = {}\n",
    "for event_id in train_events['event_id']:\n",
    "    event_data = df[df['event_id'] == event_id]\n",
    "    train_envs[event_id] = EarningsEventEnv(event_data)\n",
    "\n",
    "test_envs = {}\n",
    "for event_id in test_events['event_id']:\n",
    "    event_data = df[df['event_id'] == event_id]\n",
    "    test_envs[event_id] = EarningsEventEnv(event_data)\n",
    "\n",
    "print(f'\\n\u2713 Created {len(train_envs)} training + {len(test_envs)} test environments')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Test Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = train_envs[list(train_envs.keys())[0]]\n",
    "state = env.reset()\n",
    "\n",
    "print(f'Initial State: {state}')\n",
    "print(f'State Shape: {state.shape}')\n",
    "print(f'State Type: {state.dtype}')\n",
    "\n",
    "# Run a few steps\n",
    "done = False\n",
    "step = 0\n",
    "while not done and step < 10:\n",
    "    action = np.random.choice([0, 1, 2])\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    step += 1\n",
    "\n",
    "print(f'\\nAfter {step} steps:')\n",
    "print(f'  Reward (intermediate): {reward}')\n",
    "print(f'  Position: {env.position}')\n",
    "print(f'  Cash: ${env.cash:.2f}')\n",
    "print(f'  Window PnL: {env.get_window_pnl():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Verify State, Action, Reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = train_envs[list(train_envs.keys())[0]]\n",
    "state = env.reset()\n",
    "\n",
    "print('\u2713 STATE VERIFICATION:')\n",
    "print(f'  - Shape: {state.shape}')\n",
    "print(f'  - Dtype: {state.dtype}')\n",
    "print(f'  - Components: momentum={state[0]:.4f}, volatility={state[1]:.4f}, price=${state[3]:.2f}, pnl={state[6]:.4f}')\n",
    "\n",
    "print('\\n\u2713 ACTION VERIFICATION:')\n",
    "print(f'  - Action Space: {env.action_space}')\n",
    "print(f'  - Valid Actions: 0=Hold, 1=Buy, 2=Sell')\n",
    "\n",
    "print('\\n\u2713 REWARD VERIFICATION:')\n",
    "done = False\n",
    "rewards = []\n",
    "while not done:\n",
    "    action = np.random.choice([0, 1, 2])\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    rewards.append(reward)\n",
    "\n",
    "print(f'  - Intermediate rewards (should be 0): {len([r for r in rewards[:-1] if r == 0])}/{len(rewards)-1}')\n",
    "print(f'  - Final reward (Event Window PnL): {rewards[-1]:.6f}')\n",
    "print(f'\\n\u2705 All verifications passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('''\n",
    "\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n",
    "\u2551                   ENVIRONMENT BUILDING COMPLETE \u2705                             \u2551\n",
    "\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n",
    "\n",
    "\ud83d\udcca SUMMARY:\n",
    "\n",
    "1. STATE SPACE: 7-dimensional Box(float32)\n",
    "2. ACTION SPACE: 3 discrete actions (Discrete(3))\n",
    "3. REWARD: Event Window PnL\n",
    "4. ENVIRONMENTS: {} training + {} test\n",
    "5. TRANSACTION COST: 0.05%\n",
    "6. DATA: {} rows from CSV\n",
    "\n",
    "\u2705 All environments ready for RL training!\n",
    "\n",
    "'''.format(len(train_envs), len(test_envs), len(df)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
